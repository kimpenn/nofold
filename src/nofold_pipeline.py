#=================================================================================================
# Sarah Middleton
# 
# nofold_pipeline.py
# Pipeline automates steps from bitscore file -> clusters.
# **Run this script from from within the src directory. (Will make this more flexible in update)
# 
# Required args: 
#    BITSCORE_FILE = path to .bitscore file. 
#    FASTA_FILE = path to original fasta file of sequences
#    --bounds-file or --bounds (see below)
# 
# Notes:
#    -Everything will be output in the same folder as the bitscore file.
#    -This script expects that the sequence fasta file has the same name as the first part of the
#     bitscore file and is present in the same folder as the bitscore file. If you 
#     used score_and_normalize.py to generate your bitscore file, then this should already be  
#     taken care of for you.
#    -You must specify either --bounds-file or --bounds. The former is recommended. See README for 
#     more info.
#
# Example usage:
# python nofold_pipeline.py ../demo/demo1/demo1.zNorm.pcNorm100.zNorm.bitscore ../demo/demo1/demo1.db  --bounds-file=../thresh/bounds_30seq.txt --verbose --cpus=4 --rnaz
#=================================================================================================


if __name__ == '__main__':
	import sys, random, time, os, subprocess, glob, math, imp #needed for scripts called by this script
	import optparse
	from multiprocessing import Pool, cpu_count
	from utils_file_readers import *
	from utils_analysis import *
	
	print ""
	startAll = time.time()
	
	usageMsg = "Usage: %prog BITSCORE_FILE FASTA_FILE [options]\n    **You must specify either --bounds-file (recommended) or --bounds**"
	parser = optparse.OptionParser(usage=usageMsg)
	groupCommon = optparse.OptionGroup(parser, 'Common options')
	groupEnrich = optparse.OptionGroup(parser, 'Enrichment testing')
	groupClust = optparse.OptionGroup(parser, 'Clustering tweaks')
	groupAdv = optparse.OptionGroup(parser, 'Advanced options')
	
	groupCommon.add_option("--cpus", action="store", type='int', default=1, dest="MAX_CPUS", help="Maximum number of threads to use. Default is [%default].")
	groupCommon.add_option("--bounds-file", action="store", default=None, dest="BOUNDS_FILE", help="Bounds/threshold file, as generated by calculate_cluster_thresh.py. Overrides --bounds.")
	groupCommon.add_option("--rnaz", action="store_true", default=False, dest="RNAZ", help="Use RNAz to annotate clusters? Default is [%default].")
	groupCommon.add_option("--verbose", action="store_true", default=False, dest="VERBOSE", help="Print output from called scripts. May give better indications of progress.")
	groupCommon.add_option("--infernal-path", action="store", default=None, dest="INFERNAL_PATH", help="Path to Infernal executables. Default is to assume they have been added to your PATH and can be called by name.")
	groupCommon.add_option("--locarna-path", action="store", default=None, dest="LOCARNA_PATH", help="Path to LocARNA executables. Default is to assume they have been added to your PATH and can be called by name.")
	groupCommon.add_option("--rnaz-path", action="store", default=None, dest="RNAZ_PATH", help="Path to RNAz executable. Default is to assume it has been added to your PATH and can be called by name. This is ignored unless --rnaz is also specified.")
	
	groupEnrich.add_option("--bg-id", action="store", default=None, dest="BG_ID", help="Common id of bg seqs. Should be first part of ID, separated from the rest of the ID by an underscore. Needed for use of --bg-db")
	groupEnrich.add_option("--bg-db", action="store", default=None, dest="BG_DB", help="Fasta file of bg seqs. Only needed if doing enrichment test.")
	
	groupClust.add_option("--min-clust-size", action="store", type='int', default=3, dest="MIN_CLUST_SIZE", help="Minimum size cluster to be considered. All smaller clusters will be discarded. Default is [%default].")
	groupClust.add_option("--bit-thresh", action="store", type='float', default=None, dest="BIT_THRESH", help="Bitscore threshold to use while expanding clusters using Infernal cmsearch. Default is log2(db size).")
	groupClust.add_option("--merge", action="store", type='float', default=0.5, dest="MERGE_FRAC", help="Fraction of two clusters that must overlap for the two clusters to be merged. Default is [%default].")

	groupAdv.add_option("--bounds", action="store", default=None, dest="BOUNDS", help="Two upper bounds to use for filtering by similarity. Must be specified if --bounds-file is not. Fmt: int,int. First number should be the less stringent (higher) thresh, second is more stringent.")
	groupAdv.add_option("--orig-bs", action="store", default=None, dest="ORIG_BS", help="Original scaled bitscore file, e.g. db_name.zNorm.bitscore. Used for annotating which CMs scored highly in a cluster. Default is to assume this file is in the same folder as the supplied bitscore file.")
	groupAdv.add_option("--clust-method", action="store", dest="CLUST_METHOD", default="hierarchical", help="Method for clustering sequences. Currently, the only choice is 'hierarchical'")
	groupAdv.add_option("--hclust-method", action="store", dest="HCLUST_METHOD", default="average", help="Method for hierarchical clustering. Choices: anything that works with hclust in R. Note that if you change this, you must generate an appropriate threshold file using the same settings.")
	groupAdv.add_option("--hclust-dist", action="store", dest="HCLUST_DIST", default="spearman", help="Distance measure for hierarchical clustering. Choices: euclidean, pearson, spearman (default). For the corr measures, (1-corr) is used. Note that if you change this, you must generate an appropriate threshold file using the same settings.")
	groupAdv.add_option("--filter", action="store", default="specific", dest="FILTER", help="Type of filtering for clusters. Choices: specific, sensitive. Default is [%default].")
	groupAdv.add_option("--calibrate", action="store_true", default=False, dest="CALIBRATE", help="Calibrate cluster-CMs before expanding, allowing the used of an E-value threshold. Warning: this can take a VERY long time. Default is [%default]")
	groupAdv.add_option("--e-val", action="store", type='float', default=1, dest="E_THRESH", help="E-value threshold to use while expanding clusters using Infernal cmsearch. Default is [%default]. Only used if --calibrate is specified.")
	groupAdv.add_option("--scale", action="store_true", default=False, dest="SCALE", help="Standardize the input bitscore file? Default is False, since the input bitscore files are usually already scaled by score_and_normalize.py.")
	groupAdv.add_option("--scale-file", action="store", default=" ", dest="SCALE_FILE", help="A file containing pre-determined means and variances for each feature, as generated in calculate_universal_scale.py. Default is none. This should only be used with the --scale option.")
	
	
	
	# read/process args
	parser.add_option_group(groupCommon)
	parser.add_option_group(groupEnrich)
	parser.add_option_group(groupClust)
	parser.add_option_group(groupAdv)
	(opts, args) = parser.parse_args()
	if len(args) == 2:
		BITSCORE_FILE = os.path.abspath(os.path.expanduser(args[0]))
		FASTA_FILE = os.path.abspath(os.path.expanduser(args[1]))
	else:
		print "Incorrect args."
		print "Use -h for help. Exiting."
		sys.exit()
	
	
	# usage flags, option possibilities
	validClustMethods = ["hierarchical"]
	validHclustDists = ["euclidean", "pearson", "spearman"]
	validFilters = {"specific":"Spec", "sensitive":"Sens", "advanced":"Adv"}
	
	
	# important files
	OUT_FOLDER = os.path.dirname(BITSCORE_FILE)
	fn = os.path.basename(BITSCORE_FILE)
	fnParts = fn.split(".")
	DB_NAME = fnParts[0]
	ORIG_BS = "%s/%s.zNorm.bitscore" % (OUT_FOLDER, DB_NAME)
	CLUSTER_FILE = "%s/%s.%s" % (OUT_FOLDER, DB_NAME, opts.CLUST_METHOD)
	
	
	#----------------------------------------------------------------------------------------
	# Attempt to check to make sure everything will work 
	#----------------------------------------------------------------------------------------
	error = False
	
	(seqs, ioerror) = read_fasta(FASTA_FILE)
	if ioerror:
		print ">>Could not find specified fasta file ('%s')." % (FASTA_FILE)
		error = True
	
	if opts.INFERNAL_PATH == None:
		INFERNAL_PATH = "''"
	else:
		if not os.path.exists(opts.INFERNAL_PATH):
			error = True
			print ">>Could not find specified Infernal path (%s)" % opts.INFERNAL_PATH
		INFERNAL_PATH = os.path.abspath(opts.INFERNAL_PATH) + "/"
	
	if opts.LOCARNA_PATH == None:
		LOCARNA_PATH = "''"
	else:
		if not os.path.exists(opts.LOCARNA_PATH):
			error = True
			print ">>Could not find specified LocARNA path (%s)" % opts.LOCARNA_PATH
		LOCARNA_PATH = os.path.abspath(opts.LOCARNA_PATH) + "/"
	
	if opts.RNAZ_PATH == None:
		RNAZ_PATH = "''"
	else:
		if not os.path.exists(opts.RNAZ_PATH):
			error = True
			print ">>Could not find specified RNAz path (%s)" % opts.RNAZ_PATH
		RNAZ_PATH = os.path.abspath(opts.RNAZ_PATH) + "/"
	
	if opts.RNAZ == True:
		RNAZ = "--rnaz" 
	else:
		RNAZ = ""
	
	if opts.CLUST_METHOD != None:
		if opts.CLUST_METHOD not in validClustMethods:
			error = True
			print ">>Invalid argument for --clust-method. Valid arguments:"
			for id in validClustMethods: print "  ", id
	
	if opts.HCLUST_DIST != None:
		if opts.HCLUST_DIST not in validHclustDists:
			error = True
			print ">>Invalid argument for --hclust-dist. Valid arguments:"
			for id in validHclustDists: print "  ", id
	
	if (opts.BOUNDS_FILE == None) and (opts.BOUNDS == None):
		error = True
		print ">>Must specify --bounds or --bounds-file."
	else:
		if opts.BOUNDS_FILE != None:
			BOUNDS_FILE = os.path.abspath(opts.BOUNDS_FILE)
		else:
			BOUNDS_FILE = opts.BOUNDS
	
	if (opts.BG_DB == None):
		print "**Note: no bg database was provided, so enrichment will not be calculated."
		DO_ENRICH = False
	else:
		if (opts.BG_ID == None): #a bg was provided, but not a bg id
			error = True
			print ">>Must specify --bg-id with --bg-db"
		else:
			DO_ENRICH = True
	
	if (opts.FILTER not in validFilters):
		error = True
		print ">>Did not recognize filter:", opts.FILTER
	
	if (opts.MIN_CLUST_SIZE < 0):
		error = True
		print ">>Invalid arg for --min-clust-size:", opts.MIN_CLUST_SIZE
	
	if (opts.ORIG_BS != None):
		ORIG_BS = os.path.abspath(opts.ORIG_BS)
		
	if (opts.CALIBRATE == True):
		THRESH = opts.E_THRESH
		THRESH_ARG = "--ethresh=%s" % THRESH
		THRESH_STR = "e%s" % THRESH
		CALIB_ARGS = "--forecast --calibrate"
	else:
		if opts.E_THRESH != 1:
			print "Warning: --e-val will be ignored unless --calibrate is specified."
		if opts.BIT_THRESH == None:
			dbSize = get_db_size(seqs)
			THRESH = "%.2f" % (float(math.log10(dbSize)) / math.log10(2))
			print "**Note: A bitscore threshold of %s will be used during the expand/merge stage." % THRESH
		else:
			THRESH = opts.BIT_THRESH
		THRESH_ARG = "--bit-thresh=%s" % THRESH
		THRESH_STR = "bs%s" % THRESH
		CALIB_ARGS = ""
	
	print ""
	
	# if something was wrong, exit
	if error == True:
		print "\nOne or more errors found. Exiting.\n"
		sys.exit()
	
	
	
	#----------------------------------------------------------------------------------------
	# Set up file names/other constants
	#----------------------------------------------------------------------------------------
	ADV_SCI = 0.75
	ADV_RATIO = 1.0
	MAX_SIZE_ANNOT = 100
	FILTERED_1 =  "%s/%s.clusters" % (OUT_FOLDER, DB_NAME)
	FILTERED_1_EXT = "%s_s%sr%s_top.txt" % (FILTERED_1, opts.MIN_CLUST_SIZE, validFilters[opts.FILTER])
	FILTERED_2 = "%s_expanded_merged_%sbgNoneGloc.txt" % (FILTERED_1_EXT, THRESH_STR)
	GENE_LIST_1 = "%s_geneList.txt" % (FILTERED_1)
	GENE_LIST_2 = "%s_exp-merged_geneList.txt" % (FILTERED_1)
	STRUCT_OPTS = "--free-endgaps --indel=-100 --threads=%s" % (opts.MAX_CPUS)
	STRUCT_FOLDER = "%s/%s_structs/" % (OUT_FOLDER, DB_NAME)
	
	print "Beginning clustering with the following input files:"
	print "   Main bitscore file:", BITSCORE_FILE
	print "   zNorm bitscore file for annotation:", ORIG_BS
	print "   Bounds:", BOUNDS_FILE
	print "   Background db:", opts.BG_DB
	print ""
	
	
	
	#----------------------------------------------------------------------------------------
	# Begin NoFold clustering pipeline.
	#
	# Note: below this point, individual steps may be commented out (if, for example, you 
	# would like to restart the pipeline at a certain step). As long as the previous steps 
	# were successfully run before and all the output files are still present in the folder, 
	# there is no need to re-run those steps.
	#----------------------------------------------------------------------------------------
	
	
	# Step "cluster": get clusters
	print ""
	print "---------------------"
	print "Step 1: 'cluster'"
	stepStart = time.time()
	if opts.CLUST_METHOD == "hierarchical":
		command = 'Rscript get_clusters.r "%s" "%s" "%s" "%s" "%s" "%s"' % (BITSCORE_FILE, CLUSTER_FILE, opts.SCALE, opts.HCLUST_METHOD, opts.SCALE_FILE, opts.HCLUST_DIST)
		(output, res, error) = run_command(command, verbose=opts.VERBOSE)
		if error:
			print ">>Error detected. Exiting."
			sys.exit()
		
	else:
		print "Did not recognize argument for --clust-method. Exiting."
		sys.exit()
	print ">>> Time elapsed during this step: %.3f seconds"  % (time.time() - stepStart)
	
	
	
	# Step "filter1": filter first set of clusters
	print ""
	print "---------------------"
	print "Step 2: 'filter1'"
	stepStart = time.time()
	command = "python filter_clusters2.py %s %s %s %s %s %s %s %s %s" % (CLUSTER_FILE+".clusters", CLUSTER_FILE+".distMatrix", BOUNDS_FILE, FILTERED_1, opts.MIN_CLUST_SIZE, opts.FILTER, FASTA_FILE, ADV_SCI, ADV_RATIO)
	(output, res, error) = run_command(command, verbose=opts.VERBOSE)
	if error:
		print ">>Error detected. Exiting."
		sys.exit()
	print ">>> Time elapsed during this step: %.3f seconds"  % (time.time() - stepStart)
	
	
	
	
	# Step "annotate1": annotate first set of clusters
	print ""
	print "---------------------"
	print "Step 3: 'annotate1'"
	stepStart = time.time()
	command = 'python functional_analysis_clusters.py %s %s %s --seqsOut=%s --struct="%s" --cmA --maxSize=%s %s --aln --locarna-path=%s --rnaz-path=%s' % (FILTERED_1_EXT, FASTA_FILE, ORIG_BS, STRUCT_FOLDER, STRUCT_OPTS, MAX_SIZE_ANNOT, RNAZ, LOCARNA_PATH, RNAZ_PATH)
	(output, res, error) = run_command(command, verbose=opts.VERBOSE)
	if error:
		print ">>Error detected. Exiting."
		sys.exit()
	print ">>> Time elapsed during this step: %.3f seconds"  % (time.time() - stepStart)
	
	
	
	
	# Step "makeCM1": make and calibrate CMs
	print ""
	print "---------------------"
	print "Step 4: 'makeCM1'"
	stepStart = time.time()
	command = "python train_cms.py %s --cpu=%s --build %s --infernal-path=%s" % (FILTERED_1_EXT, opts.MAX_CPUS, CALIB_ARGS, INFERNAL_PATH)
	(output, res, error) = run_command(command, verbose=opts.VERBOSE)
	if error:
		print ">>Error detected. Exiting."
		sys.exit()
	print ">>> Time elapsed during this step: %.3f seconds"  % (time.time() - stepStart)
	
	
	
	
	
	# Step "expandMerge": expand and merge
	print ""
	print "---------------------"
	print "Step 5: 'expandMerge'"
	stepStart = time.time()
	command = "python expand_clusters.py %s %s --dist-matrix=%s --cpu=%s %s --merge=%s --glocal --infernal-path=%s" % (FILTERED_1_EXT, FASTA_FILE, CLUSTER_FILE+".distMatrix", opts.MAX_CPUS, THRESH_ARG, opts.MERGE_FRAC, INFERNAL_PATH)
	(output, res, error) = run_command(command, verbose=opts.VERBOSE)
	if error:
		print ">>Error detected. Exiting."
		sys.exit()
	print ">>> Time elapsed during this step: %.3f seconds"  % (time.time() - stepStart)
	
	
	
	
	
	# Step "annotate2": annotate expanded cluster
	print ""
	print "---------------------"
	print "Step 6: 'annotate2'"
	stepStart = time.time()
	command = 'python functional_analysis_clusters.py %s %s %s --seqsOut=%s --struct="%s" --cmA --maxSize=%s %s --aln --locarna-path=%s --rnaz-path=%s' % (FILTERED_2, FASTA_FILE, ORIG_BS, STRUCT_FOLDER, STRUCT_OPTS, MAX_SIZE_ANNOT, RNAZ, LOCARNA_PATH, RNAZ_PATH)
	(output, res, error) = run_command(command, verbose=opts.VERBOSE)
	if error:
		print ">>Error detected. Exiting."
		sys.exit()
	print ">>> Time elapsed during this step: %.3f seconds"  % (time.time() - stepStart)
	
	
	'''
	
	# Step "makeCM2": calibrate final CMs
	print ""
	print "---------------------"
	print "Step 7: 'makeCM2'"
	stepStart = time.time()
	command = "python train_cms.py %s --cpu=%s --build %s --infernal-path=%s" % (FILTERED_2+".summary", opts.MAX_CPUS, CALIB_ARGS, INFERNAL_PATH)
	(output, res, error) = run_command(command, verbose=opts.VERBOSE)
	if error:
		print ">>Error detected. Exiting."
		sys.exit()
	print ">>> Time elapsed during this step: %.3f seconds"  % (time.time() - stepStart)
	
	
	
	
	
	# Step "testEnrich": check for enrichment
	print ""
	print "---------------------"
	print "Step 8: 'testEnrich'"
	stepStart = time.time()
	if DO_ENRICH == True:
		command = "python expand_clusters.py %s %s --cpu=%s %s --bg=%s --bg-id=%s --glocal --infernal-path=%s" % (FILTERED_2+".summary", FASTA_FILE, opts.MAX_CPUS, THRESH_ARG, opts.BG_DB, opts.BG_ID, INFERNAL_PATH)
		(output, res, error) = run_command(command, verbose=opts.VERBOSE)
		if error:
			print ">>Error detected. Exiting."
			sys.exit()
	else:
		print "   No bg file was given, so enrichment cannot be calculated. Skipping this step."
		print ""
	print ">>> Time elapsed during this step: %.3f seconds"  % (time.time() - stepStart)
	
	
	'''
	
	
	# finish, clean-up
	endAll = time.time()
	print "Analysis completed."
	print "Total time: %.3f seconds (%.3f hours)" % ((endAll - startAll), float(endAll - startAll) / 60 / 60)
	
	